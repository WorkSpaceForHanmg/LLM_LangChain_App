{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dcfdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"http://127.0.0.1:11434\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b981ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "('<think>\\n'\n",
      " \"Okay, so I'm trying to understand what LangChain is. From the definition \"\n",
      " \"provided, it looks like it's a framework that brings together language \"\n",
      " 'models with other components of machine learning pipelines. That sounds '\n",
      " 'pretty broad, but let me break it down.\\n'\n",
      " '\\n'\n",
      " 'First, I know that language models are systems that can generate text based '\n",
      " \"on some input. They're used in tasks like text translation, summarization, \"\n",
      " 'and even creative writing. So LangChain must be something that uses these '\n",
      " 'models in a more integrated way with other machine learning tools.\\n'\n",
      " '\\n'\n",
      " 'The framework includes components like data pre-processing, feature '\n",
      " 'engineering, model training, inference, evaluation, deployment, and '\n",
      " 'post-processing. That makes sense because any machine learning pipeline '\n",
      " 'would need various steps to process data, build models, make predictions, '\n",
      " 'assess results, etc.\\n'\n",
      " '\\n'\n",
      " 'I wonder how LangChain specifically integrates these components with '\n",
      " 'language models. For example, does it handle the entire pipeline from data '\n",
      " 'loading through model training and inference all in one place? Or does it '\n",
      " 'separate these tasks for better control?\\n'\n",
      " '\\n'\n",
      " \"Also, I'm curious about the benefits of using a single framework like \"\n",
      " 'LangChain over integrating different tools separately. Maybe it allows for '\n",
      " 'easier customization, better resource management, or more efficient '\n",
      " 'deployment across different environments.\\n'\n",
      " '\\n'\n",
      " 'I should consider where someone might use LangChain. Probably developers '\n",
      " 'working on NLP projects who want to leverage existing language models '\n",
      " 'without re-inventing them. It could also be used in more complex '\n",
      " 'applications that require a broader range of machine learning tasks.\\n'\n",
      " '\\n'\n",
      " \"However, I'm not sure how widely supported LangChain is or if there are any \"\n",
      " 'limitations to its capabilities. Maybe some challenges like dependency '\n",
      " 'management or handling large-scale data across different platforms could '\n",
      " 'pose issues.\\n'\n",
      " '\\n'\n",
      " 'Overall, I think LangChain is a valuable tool for anyone looking to work '\n",
      " 'with language models in a comprehensive and efficient way within machine '\n",
      " 'learning pipelines. It offers flexibility and integration potential, but it '\n",
      " 'might also have some underlying complexities that require more expertise to '\n",
      " 'fully utilize.\\n'\n",
      " '</think>\\n'\n",
      " '\\n'\n",
      " 'LangChain is a comprehensive framework designed to integrate language models '\n",
      " 'into machine learning workflows seamlessly. It combines various components '\n",
      " 'of machine learning, such as data pre-processing, feature engineering, model '\n",
      " 'training, inference, evaluation, deployment, and post-processing, all within '\n",
      " 'one cohesive system. This integration allows users to efficiently manage the '\n",
      " 'entire pipeline from data handling through model training and inference.\\n'\n",
      " '\\n'\n",
      " 'Key features include flexibility for customization, better resource '\n",
      " 'management, and efficient deployment across different environments. '\n",
      " 'LangChain is beneficial for developers working on NLP projects looking to '\n",
      " 'leverage existing models without re-inventing them, as well as those '\n",
      " 'tackling complex applications requiring a broader range of machine learning '\n",
      " 'tasks.\\n'\n",
      " '\\n'\n",
      " 'While widely supported, challenges like dependency management and handling '\n",
      " 'large-scale data may require more expertise. Overall, LangChain offers '\n",
      " 'flexibility and integration potential but presents some complexities that '\n",
      " 'necessitate further exploration for full utilization.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pprint import pprint\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 deepseek-r1:1.5b 모델 로드\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "\n",
    "# 더 정확한 응답을 위한 개선된 프롬프트\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that provides accurate and detailed answers.\"),\n",
    "    (\"human\", \"Q: {question}\\nA:\")\n",
    "])\n",
    "\n",
    "\n",
    "# 최신 LangChain 방식: RunnableSequence 활용\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# 실행 예시\n",
    "question = \"What is LangChain?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(type(response))\n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629ace4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking \"파이썬은 무엇인가요?\" which means \"What is Python?\" in Korean. I need to provide a clear and accurate answer. Let me start by defining Python as a programming language. It's known for being easy to learn and powerful. Mentioning its use in various fields like web development, data analysis, machine learning, and more would be helpful. I should also highlight its simplicity and readability, maybe mention the indentation instead of braces. Oh, and the fact that it's open-source and has a large community. Maybe include some key features like dynamic typing, garbage collection, and the extensive standard library. Also, note that it's used in both small scripts and large-scale applications. I should keep the explanation concise but comprehensive. Let me check if there's any recent update or change in Python's features that I should mention. No, the basics are still relevant. Alright, structure the answer with an introduction, key features, applications, and a conclusion.\n",
      "</think>\n",
      "\n",
      "파이썬은 **프로그래밍 언어**로, 간결하고 명확한 문법을 특징으로 하는 언어입니다. 2000년대 초반에 비주절로 개발된 Python은 **동적 타입**과 **간결한 문법**으로 인해 초보자도 쉽게 배워볼 수 있는 언어로 유명합니다. \n",
      "\n",
      "### 주요 특징:\n",
      "1. **간결한 문법**: 들여쓰기(인덴트)로 구분하는 방식이 대표적입니다.  \n",
      "   - 예: `if x > 0: print(\"Positive\")`  \n",
      "   - 다른 언어는 `{}`로 코드를 묶는 반면, 파이썬은 들여쓰기만으로 구분합니다.\n",
      "\n",
      "2. **다양한 활용 분야**:  \n",
      "   - **웹 개발** (Django, Flask), **데이터 분석** (Pandas, NumPy), **머신러닝** (Scikit-learn), **게임 개발** (Pygame), **제어 시스템**, **보안**, **모바일 개발** 등 다양한 분야에서 사용됩니다.\n",
      "\n",
      "3. **활용 범위**:  \n",
      "   - 작은 스크립트 작성부터 대규모 애플리케이션까지, 다양한 규모의 프로젝트에서 사용됩니다.\n",
      "\n",
      "4. **열린 소스 & 커뮤니티**:  \n",
      "   - 오픈 소스로 제공되며, 대규모의 커뮤니티와 라이브러리가 존재해 빠르게 배우고 활용할 수 있습니다.\n",
      "\n",
      "5. **다양한 라이브러리**:  \n",
      "   - 파이썬의 표준 라이브러리(Standard Library)와 추가 라이브러리(예: Django, TensorFlow)가 풍부하여 다양한 기능을 제공합니다.\n",
      "\n",
      "### 예시:\n",
      "```python\n",
      "# 간단한 계산\n",
      "result = 5 + 3\n",
      "print(result)  # 출력: 8\n",
      "```\n",
      "\n",
      "### 결론:\n",
      "파이썬은 **다양한 분야에서 활용 가능한 강력한 언어**로, 간결함과 편의성의 균형을 유지하면서도 확장성과 풍부한 기능을 제공합니다. 초보자부터 명확한 프로그래밍 습관을 키우는 데 도움이 되며, 현대 기술의 핵심 언어 중 하나입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 qwen3:1.7b 모델 로드\n",
    "llm = ChatOllama(model=\"qwen3:1.7b\")\n",
    "\n",
    "# 더 정확한 응답을 위한 개선된 프롬프트\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that provides accurate and detailed answers.\"),\n",
    "    (\"human\", \"Q: {question}\\nA:\")\n",
    "])\n",
    "\n",
    "# 최신 LangChain 방식: RunnableSequence 활용\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# 실행 예시\n",
    "question = \"파이썬은 무엇인가요?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-langchain-app-main-JUdlSi0d-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
